# Java Driver configuration for DSBulk.
#
# The settings below are just a subset of all the configurable options of the driver, and provide
# an optimal driver configuration for DSBulk for most use cases. See the Java Driver configuration
# reference for instructions on how to configure the driver properly:
# https://docs.datastax.com/en/developer/java-driver/4.3/manual/core/configuration
#
# Note that a paragraph is written in one line, and paragraphs are separated by a blank line.
# This has the benefit of rendering well in markdown as well as plain-text help output (since
# the help text formatter wraps lines appropriately).
#
# Also note that the order of declaration of settings in this file will be preserved in generated
# documentation (help on the command line and generated setting.md file).
# See com.datastax.dsbulk.engine.internal.help.HelpEmitter and
# com.datastax.dsbulk.engine.internal.docs.SettingsDocumentor.
#
# For this reason, usage of references in this file should be avoided.
#
# Finally, this file will also be parsed and prettified when generating the configuration template
# for DSBulk + driver, see com.datastax.dsbulk.engine.internal.docs.ConfigurationFileCreator.
datastax-java-driver {

  # Basic options.
  basic {

    # The contact points to use for the initial connection to the cluster.
    #
    # These are addresses of Cassandra nodes that the driver uses to discover the cluster topology. Only one contact point is required (the driver will retrieve the address of the other nodes automatically), but it is usually a good idea to provide more than one contact point, because if that single contact point is unavailable, the driver cannot initialize itself correctly.
    #
    # This must be a list of strings with each contact point specified as "host" or "host:port". If the specified host doesn't have a port, the default port specified in `basic.default-port` will be used. Note that Cassandra 3 and below and DSE 6.7 and below require all nodes in a cluster to share the same port (see CASSANDRA-7544).
    #
    # If the host is a DNS name that resolves to multiple A-records, all the corresponding addresses will be used. Do not use "localhost" as the host name (since it resolves to both IPv4 and IPv6 addresses on some platforms).
    #
    # The heuristic to determine whether or not a contact point is in the form "host" or "host:port" is not 100% accurate for some IPv6 addresses; you should avoid ambiguous IPv6 addresses such as `fe80::f861:3eff:fe1d:1234`, because such a string can be seen either as a combination of IP `fe80::f861:3eff:fe1d` with port 1234, or as IP `fe80::f861:3eff:fe1d:1234` without port. In such cases, DSBulk will not change the contact point. This issue can be avoided by providing IPv6 addresses in full form, e.g. if instead of `fe80::f861:3eff:fe1d:1234` you provide `fe80:0:0:0:0:f861:3eff:fe1d:1234`, then the string is unequivocally parsed as IP `fe80:0:0:0:0:f861:3eff:fe1d` with port 1234.
    #
    # Note: on Cloud deployments, DSBulk automatically sets this option to an empty list, as contact points are not allowed to be explicitly provided when connecting to DataStax Apollo databases.
    # @type list<string>
    contact-points = ["127.0.0.1:9042"]

    # The default port to use for `basic.contact-points`, when a host is specified without port. Note that Cassandra 3 and below and DSE 6.7 and below require all nodes in a cluster to share the same port (see CASSANDRA-7544). If this setting is not specified, the default port will be 9042.
    default-port = 9042

    # Options for connection to a DataStax Apollo database.
    cloud {

      # The location of the secure bundle used to connect to a Datastax Apollo database. This setting must be a path on the local filesystem or a valid URL.
      #
      # Examples:
      #
      #     "/path/to/bundle.zip"          # path on *Nix systems
      #     "./path/to/bundle.zip"         # path on *Nix systems, relative to workding directory
      #     "~/path/to/bundle.zip"         # path on *Nix systems, relative to home directory
      #     "C:\\path\\to\\bundle.zip"     # path on Windows systems,
      #                                    # note that you need to escape backslashes in HOCON
      #     "file:/a/path/to/bundle.zip"   # URL with file protocol
      #     "http://host.com/bundle.zip"   # URL with HTTP protocol
      #
      # Note: if you set this to a non-null value, DSBulk assumes that you are connecting to an DataStax Apollo database; in this case, you should not set any of the following settings because they are not compatible with Cloud deployments:
      #
      # - `datastax-java-driver.basic.contact-points`
      # - `datastax-java-driver.basic.request.consistency`
      # - `datastax-java-driver.advanced.ssl-engine-factory.*`
      #
      # If you do so, a log will be emitted and the setting will be ignored.
      # @type string
      secure-connect-bundle = null

    }

    request {

      # How long the driver waits for a request to complete. This is a global limit on the duration of a session.execute() call, including any internal retries the driver might do. By default, this value is set very high because DSBulk is optimized for good throughput, rather than good latencies.
      timeout = 60 seconds

      # The consistency level to use for all queries. Note that stronger consistency levels usually result in reduced throughput. In addition, any level higher than `ONE` will automatically disable continuous paging, which can dramatically reduce read throughput.
      #
      # Valid values are: `ANY`, `LOCAL_ONE`, `ONE`, `TWO`, `THREE`, `LOCAL_QUORUM`, `QUORUM`, `EACH_QUORUM`, `ALL`.
      #
      # Note: on Cloud deployments, the only accepted consistency level when writing is `LOCAL_QUORUM`. Therefore, the default value is `LOCAL_ONE`, except when loading in Cloud deployments, in which case the default is automatically changed to `LOCAL_QUORUM`.
      consistency = LOCAL_ONE

      # The serial consistency level. The allowed values are `SERIAL` and `LOCAL_SERIAL`.
      serial-consistency = LOCAL_SERIAL

      # The default idempotence for all queries executed in DSBulk. Setting this to false will cause all write failures to not be retried.
      default-idempotence = true

      # The page size. This controls how many rows will be retrieved simultaneously in a single network roundtrip (the goal being to avoid loading too many results in memory at the same time). If there are more results, additional requests will be used to retrieve them (either automatically if you iterate with the sync API, or explicitly with the async API's `fetchNextPage` method). If the value is 0 or negative, it will be ignored and the request will not be paged.
      page-size = 5000

    }

    # The load balancing policy decides the "query plan" for each query; that is, which nodes to try as coordinators, and in which order.
    load-balancing-policy {

      # The load balancing policy class to use. If it is not qualified, the driver assumes that it resides in the package `com.datastax.oss.driver.internal.core.loadbalancing`.
      #
      # DSBulk uses a special policy that infers the local datacenter from the contact points. You can also specify a custom class that implements `LoadBalancingPolicy` and has a public constructor with two arguments: the `DriverContext` and a `String` representing the profile name.
      class = com.datastax.dse.driver.internal.core.loadbalancing.DseDcInferringLoadBalancingPolicy

      # The datacenter that is considered "local": the default load balancing policy will only include nodes from this datacenter in its query plans. Set this to a non-null value if you want to force the local datacenter; otherwise, the `DseDcInferringLoadBalancingPolicy` used by default by DSBulk will infer the local datacenter from the provided contact points.
      # @type string
      local-datacenter = null

      # An optional custom filter to include/exclude nodes. This option is not required; if present, it must be the fully-qualified name of a class that implements `java.util.function.Predicate<Node>`, and has a public constructor taking a single `DriverContext` argument. The predicate's `test(Node)` method will be invoked each time the policy processes a topology or state change: if it returns false, the node will be set at distance `IGNORED` (meaning the driver won't ever connect to it), and never included in any query plan.
      # @type string
      filter.class = null

    }

  }

  # Advanced options.
  advanced {

    protocol {

      # The native protocol version to use. If this option is absent, the driver looks up the versions of the nodes at startup (by default in `system.peers.release_version`), and chooses the highest common protocol version. For example, if you have a mixed cluster with Apache Cassandra 2.1 nodes (protocol v3) and Apache Cassandra 3.0 nodes (protocol v3 and v4), then protocol v3 is chosen. If the nodes don't have a common protocol version, initialization fails. If this option is set, then the given version will be used for all connections, without any negotiation or downgrading. If any of the contact points doesn't support it, that contact point will be skipped. Once the protocol version is set, it can't change for the rest of the driver's lifetime; if an incompatible node joins the cluster later, connection will fail and the driver will force it down (i.e. never try to connect to it again).
      # @type string
      version = null

      # The name of the algorithm used to compress protocol frames. The possible values are: `lz4`, `snappy` or `none` to indicate no compression (this is functionally equivalent to omitting the option).
      compression = none

    }

    connection {

      # The driver maintains a connection pool to each node, according to the distance assigned to it by the load balancing policy. If the distance is IGNORED, no connections are maintained.
      pool {

        # The number of connections in the pool for nodes considered as local.
        local.size = 8

        # The number of connections in the pool for nodes considered as remote. Note that the default load balancing policy used by DSBulk never considers remote nodes, so this setting has no effect when using the default load balancing policy.
        remote.size = 8

      }

      # The maximum number of requests that can be executed concurrently on a connection. This must be between 1 and 32768.
      max-requests-per-connection = 32768

    }

    # The component that handles authentication on each new connection.
    auth-provider {

      # The class of the authentication provider. If it is not qualified, the driver assumes that it resides in one of the following packages:
      # - `com.datastax.oss.driver.internal.core.auth`
      # - `com.datastax.dse.driver.internal.core.auth`
      #
      # The DSE driver provides 3 implementations out of the box:
      # - `PlainTextAuthProvider`: uses plain-text credentials. It requires the `username` and `password` options. Should be used only when authenticating against Apache Cassandra(R) clusters; not recommended when authenticating against DSE clusters.
      # - `DsePlainTextAuthProvider`: provides SASL authentication using the PLAIN mechanism for DSE clusters secured with DseAuthenticator. It requires the `username` and `password` options, and optionally, an `authorization-id`.
      # - `DseGssApiAuthProvider`: provides GSSAPI authentication for DSE clusters secured with `DseAuthenticator`. Read the javadocs of this authenticator for detailed instructions.
      #
      # You can also specify a custom class that implements `AuthProvider` and has a public constructor with a `DriverContext` argument (to simplify this, the driver provides two abstract classes that can be extended: `DsePlainTextAuthProviderBase` and `DseGssApiAuthProviderBase`).
      class = null

      # The username to use to authenticate against a cluster with authentication enabled. Providers that accept this setting:
      #
      #  - `PlainTextAuthProvider`
      #  - `DsePlainTextAuthProvider`
      #
      # @type string
      username = null

      # The password to use to authenticate against a cluster with authentication enabled. Providers that accept this setting:
      #
      #  - `PlainTextAuthProvider`
      #  - `DsePlainTextAuthProvider`
      #
      # @type string
      password = null

      # An authorization ID allows the currently authenticated user to act as a different user (proxy authentication). Providers that accept this setting:
      #
      #  - `DsePlainTextAuthProvider`
      #  - `DseGssApiAuthProvider`
      #
      # @type string
      authorization-id = null

    }

    # The SSL engine factory that will initialize an SSL engine for each new connection to a server.
    ssl-engine-factory {

      # The class of the SSL engine factory. If it is not qualified, the driver assumes that it resides in the package `com.datastax.oss.driver.internal.core.ssl`. The driver provides a single implementation out of the box: `DefaultSslEngineFactory`, that uses the JDK's built-in SSL implementation.
      #
      # You can also specify a custom class that implements `SslEngineFactory` and has a public constructor with a `DriverContext` argument.
      # @type string
      class = null

      # The cipher suites to enable when creating an SSLEngine for a connection. This setting is only required when using the default SSL factory. If it is not present, the driver won't explicitly enable cipher suites on the engine, which according to the JDK documentations results in "a minimum quality of service".
      # @type list<string>
      cipher-suites = null

      # Whether or not to require validation that the hostname of the server certificate's common name matches the hostname of the server being connected to. This setting is only required when using the default SSL factory. If not set, defaults to true.
      hostname-validation = true

      # The locations used to access truststore contents. If either truststore-path or keystore-path are specified, the driver builds an SSLContext from these files. This setting is only required when using the default SSL factory. This setting is only required when using the default SSL factory. If neither option is specified, the default SSLContext is used, which is based on system property configuration.
      # @type string
      truststore-path = null

      # The password used to access truststore contents. This setting is only required when using the default SSL factory.
      # @type string
      truststore-password = null

      # The locations used to access keystore contents. If either truststore-path or keystore-path are specified, the driver builds an SSLContext from these files. This setting is only required when using the default SSL factory. If neither option is specified, the default SSLContext is used, which is based on system property configuration.
      # @type string
      keystore-path = null

      # The password used to access keystore contents. This setting is only required when using the default SSL factory.
      # @type string
      keystore-password = null
    }

    # The policy that controls if the driver retries requests that have failed on one node.
    retry-policy {

      # The class of the retry policy. If it is not qualified, the driver assumes that it resides in the package `com.datastax.oss.driver.internal.core.retry`. DSBulk uses by default a special retry policy that opinionately retries most errors up to `max-retries` times.
      #
      # You can also specify a custom class that implements `RetryPolicy` and has a public constructor with two arguments: the `DriverContext` and a `String` representing the profile name.
      class = com.datastax.dsbulk.engine.internal.policies.retry.MultipleRetryPolicy

      # How many times to retry a failed query. Only valid for use with DSBulk's default retry policy (`MultipleRetryPolicy`).
      max-retries = 10

    }

    # Whether to resolve the addresses passed to `basic.contact-points`.
    #
    # If this is true, addresses are created with `InetSocketAddress(String, int)`: the host name will be resolved the first time, and the driver will use the resolved IP address for all subsequent connection attempts. If this is false, addresses are created with `InetSocketAddress.createUnresolved()`: the host name will be resolved again every time the driver opens a new connection. This is useful for containerized environments where DNS records are more likely to change over time (note that the JVM and OS have their own DNS caching mechanisms, so you might need additional configuration beyond the driver).
    #
    # This option only applies to the contact points specified in the configuration. It has no effect on dynamically discovered peers: the driver relies on Cassandra system tables, which expose raw IP addresses. Use a custom address translator (see `advanced.address-translator`) to convert them to unresolved addresses (if you're in a containerized environment, you probably already need address translation anyway).
    resolve-contact-points = true

    # The address translator to use to convert the addresses sent by Cassandra nodes into ones that the driver uses to connect. This is only needed if the nodes are not directly reachable from the driver (for example, the driver is in a different network region and needs to use a public IP, or it connects through a proxy).
    address-translator {

      # The class of the translator. If it is not qualified, the driver assumes that it resides in the package `com.datastax.oss.driver.internal.core.addresstranslation`.
      #
      # The driver provides the following implementations out of the box:
      # - `PassThroughAddressTranslator`: returns all addresses unchanged
      #
      # You can also specify a custom class that implements `AddressTranslator` and has a public constructor with a `DriverContext` argument.
      class = PassThroughAddressTranslator

    }

    # The generator that assigns a microsecond timestamp to each request.
    timestamp-generator {

      # The class of the microsecond timestamp generator. If it is not qualified, the driver assumes that it resides in the package `com.datastax.oss.driver.internal.core.time`.
      #
      # The driver provides the following implementations out of the box:
      # - `AtomicTimestampGenerator`: timestamps are guaranteed to be unique across all client threads.
      # - `ThreadLocalTimestampGenerator`: timestamps that are guaranteed to be unique within each
      #   thread only.
      # - `ServerSideTimestampGenerator`: do not generate timestamps, let the server assign them.
      #
      # You can also specify a custom class that implements `TimestampGenerator` and has a public constructor with two arguments: the `DriverContext` and a `String` representing the profile name.
      class = AtomicTimestampGenerator

    }

    # Options to control the execution of continuous paging requests. Only applicable for unloads, and only if this feature is available in the remote cluster, ignored otherwise. Also, you need to enable continuous paging at DSBulk level for this to work, see `dsbulk.executor.continuousPaging.enabled` (it is enabled by default).
    continuous-paging {

      # The page size. The value specified here can be interpreted in number of rows or in number of bytes, depending on the unit defined with page-unit (see below). It controls how many rows (or how much data) will be retrieved simultaneously in a single network roundtrip (the goal being to avoid loading too many results in memory at the same time). If there are more results, additional requests will be used to retrieve them (either automatically if you iterate with the sync API, or explicitly with the async API's fetchNextPage method). The default is the same as the driver's normal request page size, i.e., 5000 (rows).
      page-size = 5000

      # Whether the page-size option should be interpreted in number of rows or bytes. The default is false, i.e., the page size will be interpreted in number of rows.
      page-size-in-bytes = false

      # The maximum number of pages to return. The default is zero, which means retrieve all pages.
      max-pages = 0

      # Returns the maximum number of pages per second. The default is zero, which means no limit.
      max-pages-per-second = 0

      # The maximum number of pages that can be stored in the local queue. This value must be positive. The default is 4.
      max-enqueued-pages = 4

      # Timeouts for continuous paging. Note that there is no global timeout for continuous paging as there is for regular queries, because continuous paging queries can take an arbitrarily long time to complete. Instead, timeouts are applied to each exchange between the driver and the coordinator. In other words, if the driver decides to retry, all timeouts are reset.
      timeout {

        # How long to wait for the coordinator to send the first page.
        first-page = 60 seconds

        # How long to wait for the coordinator to send subsequent pages.
        other-pages = 120 seconds

      }
    }

    heartbeat {

      # The heartbeat interval. If a connection stays idle for that duration (no reads), the driver sends a dummy message on it to make sure it's still alive. If not, the connection is trashed and replaced.
      interval = 30 seconds

      # How long the driver waits for the response to a heartbeat. If this timeout fires, the heartbeat is considered failed.
      timeout = 60 seconds

    }

    # Metrics in DSBulk are all disabled by default.
    metrics {}
  }
}
