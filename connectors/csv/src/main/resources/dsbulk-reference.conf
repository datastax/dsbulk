# Note that a paragraph is written in one line, and paragraphs are separated by a blank line.
# This has the benefit of rendering well in markdown as well as plain-text help output (since
# the help text formatter wraps lines appropriately).
dsbulk {

  # CSV Connector configuration.
  connector.csv {

    # The URL or path of the resource(s) to read from or write to.
    #
    # Which URL protocols are available depend on which URL stream handlers have been installed, but at least the **file** protocol is guaranteed to be supported for reads and writes, and the **http** and **https** protocols are guaranteed to be supported for reads.
    #
    # The file protocol can be used with all supported file systems, local or not.
    # - When reading: the URL can point to a single file, or to an existing directory; in case of a directory, the *fileNamePattern* setting can be used to filter files to read, and the *recursive* setting can be used to control whether or not the connector should look for files in subdirectories as well.
    # - When writing: the URL will be treated as a directory; if it doesn't exist, the loader will attempt to create it; CSV files will be created inside this directory, and their names can be controlled with the *fileNameFormat* setting.
    #
    # Note that if the value specified here does not have a protocol, then it is assumed to be a file protocol. Relative URLs will be resolved against the current working directory. Also, for convenience, if the path begins with a tilde (`~`), that symbol will be expanded to the current user's home directory.
    #
    # In addition the value `-` indicates `stdin` when loading and `stdout` when unloading. This is in line with Unix tools such as tar, which uses `-` to represent stdin/stdout when reading/writing an archive.
    #
    # Examples:
    #
    #     url = "/path/to/dir/or/file"           # without protocol
    #     url = "./path/to/dir/or/file"          # without protocol, relative to working directory
    #     url = "~/path/to/dir/or/file"          # without protocol, relative to the user's home directory
    #     url = "file:///path/to/dir/or/file"    # with file protocol
    #     url = "http://acme.com/file.csv"       # with HTTP protocol
    #     url = "-"                              # to read csv data from stdin (for load) or
    #     url = "-"                              # write csv data to stdout (for unload)
    #
    # For other URLs: the URL will be read or written directly; settings like *fileNamePattern*, *recursive*, and *fileNameFormat* will have no effect.
    #
    # The default value is `-` (read from `stdin` / write to `stdout`).
    url = "-"

    # The URL or path of the file that contains the list of resources to read from.
    #
    # The file specified here should be located on the local filesystem.
    #
    # This setting and `connector.csv.url` are mutually exclusive. If both are defined and non empty, this setting takes precedence over `connector.csv.url`.
    #
    # This setting applies only when loading. When unloading, this setting should be left empty or set to null; any non-empty value will trigger a fatal error.
    #
    # The file with URLs should follow this format:
    #
    # ```
    # /path/to/file/file.csv
    # /path/to.dir/
    # ```
    #
    # Every line should contain one path. You don't need to escape paths in this file.
    #
    # All the remarks for `connector.csv.url` apply for each line in the file, and especially, settings like `fileNamePattern`, `recursive`, and `fileNameFormat` all apply to each line individually.
    #
    # You can comment out a line in the URL file by making it start with a # sign:
    #
    # ```
    # #/path/that/will/be/ignored
    # ```
    #
    # Such a line will be ignored.
    #
    # For your convenience, every line in the urlfile will be trimmed - that is, any leading and trailing white space will be removed.
    #
    # The file should be encoded in UTF-8, and each line should be a valid URL to load.
    #
    # The default value is "" - which means that this property is ignored.
    urlfile = ""

    # The glob pattern to use when searching for files to read. The syntax to use is the glob syntax, as described in `java.nio.file.FileSystem.getPathMatcher()`. This setting is ignored when writing and for non-file URLs. Only applicable when the *url* setting points to a directory on a known filesystem, ignored otherwise.
    #
    # If compression is enabled, the default value for this setting will be modified to include the default suffix for the selected compression method. For example, if compression is `gzip`, the default glob pattern will be `**/*.csv.gz`.
    fileNamePattern = "**/*.csv"

    # The file name format to use when writing. This setting is ignored when reading and for non-file URLs. The file name must comply with the formatting rules of `String.format()`, and must contain a `%d` format specifier that will be used to increment file name counters.
    #
    # If compression is enabled, the default value for this setting will be modified to include the default suffix for the selected compression method. For example, if compression is `gzip`, the default file name format will be `output-%06d.csv.gz`.
    fileNameFormat = "output-%06d.csv"

    # Enable or disable scanning for files in the root's subdirectories. Only applicable when *url* is set to a directory on a known filesystem. Used for loading only.
    recursive = false

    # The maximum number of files that can be read or written simultaneously. This setting is effective only when reading from or writing to many resources in parallel, such as a collection of files in a root directory; it is ignored otherwise. The special syntax `NC` can be used to specify a number of threads that is a multiple of the number of available cores, e.g. if the number of cores is 8, then 0.5C = 0.5 * 8 = 4 threads.
    #
    # The default value is the special value AUTO; with this value, the connector will decide the best number of files.
    maxConcurrentFiles = AUTO

    # The file encoding to use for all read or written files.
    encoding = "UTF-8"

    # The compression that will be used for writing or reading files. Supported values are (for both reading and writing): `none`, `xz`, `gzip`, `bzip2`, `zstd`, `lz4`, `lzma`, `snappy`, `deflate`.  For reading only, supported values are: `brotli`, `z`, `deflate64`.
    compression = "none"

    # Enable or disable whether the files to read or write begin with a header line. If enabled for loading, the first non-empty line in every file will assign field names for each record column, in lieu of `schema.mapping`, `fieldA = col1, fieldB = col2, fieldC = col3`. If disabled for loading, records will not contain fields names, only field indexes, `0 = col1, 1 = col2, 2 = col3`. For unloading, if this setting is enabled, each file will begin with a header line, and if disabled, each file will not contain a header line.
    #
    # Note: This option will apply to all files loaded or unloaded.
    header = true

    # The character(s) to use as field delimiter. Field delimiters containing more than one character are accepted.
    delimiter = ","

    # The character used for quoting fields when the field delimiter is part of the field value. Only one character can be specified. Note that this setting applies to all files to be read or written.
    quote = "\""

    # The character used for escaping quotes inside an already quoted value. Only one character can be specified. Note that this setting applies to all files to be read or written.
    escape = "\\"

    # The character that represents a line comment when found in the beginning of a line of text. Only one character can be specified. Note that this setting applies to all files to be read or written. This feature is disabled by default (indicated by its `null` character value).
    comment = "\u0000"

    # The character(s) that represent a line ending. When set to the special value `auto` (default), the system's line separator, as determined by `System.lineSeparator()`, will be used when writing, and auto-detection of line endings will be enabled when reading. Only one or two characters can be specified; beware that most typical line separator characters need to be escaped, e.g. one should specify `\r\n` for the typical line ending on Windows systems (carriage return followed by a new line).
    newline = "auto"

    # The number of records to skip from each input file before the parser can begin to execute. Note that if the file contains a header line, that line is not counted as a valid record. This setting is ignored when writing.
    skipRecords = 0

    # The maximum number of records to read from or write to each file. When reading, all records past this number will be discarded. When writing, a file will contain at most this number of records; if more records remain to be written, a new file will be created using the *fileNameFormat* setting. Note that when writing to anything other than a directory, this setting is ignored. This setting takes into account the *header* setting: if a file begins with a header line, that line is not counted as a record. This feature is disabled by default (indicated by its `-1` value).
    maxRecords = -1

    # The maximum number of characters that a field can contain. This setting is used to size internal buffers and to avoid out-of-memory problems. If set to -1, internal buffers will be resized dynamically. While convenient, this can lead to memory problems. It could also hurt throughput, if some large fields require constant resizing; if this is the case, set this value to a fixed positive number that is big enough to contain all field values.
    maxCharsPerColumn = 4096

    # The maximum number of columns that a record can contain. This setting is used to size internal buffers and to avoid out-of-memory problems.
    maxColumns = 512

    # Defines whether or not leading whitespaces from values being read/written should be skipped. This setting is honored when reading and writing. Default value is false.
    ignoreLeadingWhitespaces = false

    # Defines whether or not trailing whitespaces from values being read/written should be skipped. This setting is honored when reading and writing. Default value is false.
    ignoreTrailingWhitespaces = false

    # Defines whether or not leading whitespaces from quoted values should be skipped. This setting is only honored when reading; it is ignored when writing. Default value is false.
    ignoreTrailingWhitespacesInQuotes = false

    # Defines whether or not trailing whitespaces from quoted values should be skipped. This setting is only honored when reading; it is ignored when writing. Default value is false.
    ignoreLeadingWhitespacesInQuotes = false

    # Defines whether or not line separators should be replaced by a normalized line separator '\n' inside quoted values. This setting is honored when reading and writing. Note: due to a bug in the CSV parsing library, on Windows systems, the line ending detection mechanism may not function properly when this setting is false; in case of problem, set this to true. Default value is false.
    normalizeLineEndingsInQuotes = false

    # Sets the String representation of a null value. When reading, if the parser does not read any character from the input, this value will be used instead. When writing, if the writer has a null object to write to the output, this value will be used instead. The default value is `AUTO`, which means that, when reading, the parser will emit a `null`, and when writing, the writer won't write any character at all to the output.
    nullValue = AUTO

    # Sets the String representation of an empty value. When reading, if the parser does not read any character from the input, and the input is within quotes, this value will be used instead. When writing, if the writer has an empty string to write to the output, this value will be used instead. The default value is `AUTO`, which means that, when reading, the parser will emit an empty string, and when writing, the writer will write a quoted empty field to the output.
    emptyValue = AUTO

    # This group of settings is purely internal to the connector and are the interface for
    # DSBulk's infrastructure to customize how some settings are exposed to the user.
    #
    # In particular, how settings are documented and shortcut options that map to
    # settings that are commonly specified in the command line.
    metaSettings {
      # Specify how settings should be prioritized in generated docs and help.
      docHints {
        commonSettings = [url, delimiter, header, skipRecords, maxRecords]
        preferredSettings = [quote]
      }

      # Specify shortcuts for "long" options.
      # Format:
      # shortcut = unqualified long option (relative to dsbulk.connector.csv).
      shortcuts {
        comment = comment
        delim = delimiter
        encoding = encoding
        escape = escape
        header = header
        newline = newline
        skipRecords = skipRecords
        maxRecords = maxRecords
        maxConcurrentFiles = maxConcurrentFiles
        quote = quote
        url = url
      }
    }
  }

}
