# Reference configuration for the CSV Connector.
#
# Note that a paragraph is written in one line, and paragraphs are separated by a blank line.
# This has the benefit of rendering well in markdown as well as plain-text help output (since
# the help text formatter wraps lines appropriately).
dsbulk.connector.csv {

  # The URL or path of the resource(s) to read from or write to.
  #
  # Which URL protocols are available depend on which URL stream handlers have been installed, but at least the following are guaranteed to be supported:
  #
  # - **stdin**:  the stdin protocol can be used to read from standard input; the only valid URL for this protocol is: `stdin:/`.
  #
  #   This protocol cannot be used for writing.
  #
  # - **stdout**: the stdout protocol can be used to write to standard output; the only valid URL for this protocol is: `stdout:/`.
  #
  #   This protocol cannot be used for reading.
  #
  # - **file**: the file protocol can be used with all supported file systems, local or not.
  #     - **When reading**: the URL can point to a single file, or to an existing directory; in case of a directory, the *pattern* setting can be used to filter files to read, and the *recursive* setting can be used to control whether or not the connector should look for files in subdirectories as well.
  #     - **When writing**: the URL will be treated as a directory; if it doesn't exist, the loader will attempt to create it; CSV files will be created inside this directory, and their names can be controlled with the *fileNameFormat* setting.
  #
  # Note that if the value specified here does not have a protocol, then it is assumed to be a file protocol.
  #
  # Examples:
  #
  #     url = /path/to/dir/or/file           # without protocol
  #     url = "file:///path/to/dir/or/file"  # with protocol
  #     url = "stdin:/"                      # to read csv data from stdin
  #     url = "stdout:/"                     # to write csv data to stdout
  #
  # For other URLs: the URL will be read or written directly; settings like *pattern*, *recursive*, and *fileNameFormat* will have no effect.
  #
  # This setting has no default value and must be supplied by the user.
  url = ""

  # The glob pattern to use when searching for files to read. The syntax to use is the glob syntax, as described in `java.nio.file.FileSystem.getPathMatcher()`.
  #
  # Ignored when writing. Ignored for non-file URLs.
  #
  # Only applicable when the *url* setting points to a directory on a known filesystem, ignored otherwise.
  pattern = "**/*.csv"

  # The file name format to use when writing.
  #
  # Ignored when reading. Ignored for non-file URLs.
  #
  # The file name must comply with the formatting rules of `String.format()`, and must contain a `%d` format specifier that will be used to increment file name counters.
  fileNameFormat = "output-%0,6d.csv"

  # Whether to scan for files in subdirectories of the root directory.
  #
  # Only applicable when the *url* setting points to a directory on a known filesystem, ignored otherwise. Ignored when writing.
  recursive = false

  # The maximum number of reading or writing threads. In other words, this setting controls how many files can be read or written simultaneously.
  maxThreads = 4

  # The file encoding to use.
  #
  # Note that this setting applies to all files to be read or written.
  encoding = "UTF-8"

  # Whether the files to read or write begin with a header line or not.
  #
  # When reading:
  #
  #  - if set to true, the first non-empty line in every file is discarded, even if the *skipLines* setting is set to zero (see below). However, that line will be used to assign field names to each record, thus allowing mappings by field name such as `{myFieldName1 = myColumnName1, myFieldName2 = myColumnName2}`.
  #  - if set to false, records will not contain field names, only (zero-based) field indexes; in this case, the mapping should be index-based, such as in `{0 = myColumnName1, 1 = myColumnName2}`.
  #
  # When writing:
  #
  #  - if set to true: each file will begin with a header line;
  #  - if set to false, files will not contain header lines.
  #
  # Note that this setting applies to all files to be read or written.
  header = false

  # The character to use as field delimiter.
  #
  # Only one character can be specified. Note that this setting applies to all files to be read or written.
  delimiter = ","

  # The character used for quoting fields when the field delimiter is part of the field value.
  #
  # Only one character can be specified. Note that this setting applies to all files to be read or written.
  quote = "\""

  # The character used for escaping quotes inside an already quoted value.
  #
  # Only one character can be specified. Note that this setting applies to all files to be read or written.
  escape = "\\"

  # The character that represents a line comment when found in the beginning of a line of text.
  #
  # Only one character can be specified. Note that this setting applies to all files to be read or written.
  #
  # This feature is disabled by default (indicated by its `null` character value).
  comment = "\u0000"

  # Defines a number of lines to skip from each input file before the parser can begin to execute.
  #
  # Ignored when writing.
  skipLines = 0

  # Defines the maximum number of lines to read from or write to each file.
  #
  # When reading, all lines past this number will be discarded.
  #
  # When writing, a file will contain at most this number of lines; if more records remain to be written, a new file will be created using the *fileNameFormat* setting.
  #
  # Note that when writing to anything other than a directory, this setting is ignored.
  #
  # This setting takes into account the *header* setting: if a file begins with a header line, that line is counted.
  #
  # This feature is disabled by default (indicated by its `-1` value).
  maxLines = -1

}
