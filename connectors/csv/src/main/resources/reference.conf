# Reference configuration for the CSV Connector.
datastax-loader.connector.csv {

  # The URL or path of the resource(s) to read from or write to.
  # This setting has no default value and must be supplied by the user.
  # Which URL protocols are available depend on which URL stream handlers
  # have been installed, but at least one protocol is guaranteed to be supported:
  # - file:   the file protocol can be used with all supported file systems, local or not.
  #           When reading: the URL can point to a single file, or to an existing directory;
  #           in case of a directory, the "pattern" setting can be used to filter files to read,
  #           and the "recursive" setting can be used to control whether or
  #           not the connector should look for files in subdirectories as well.
  #           When writing: the URL will be treated as a directory; if it doesn't exist,
  #           the loader will attempt to create it; CSV files will be created inside
  #           this directory, and their names can be controlled
  #           with the "fileNameFormat" setting.
  #           Note that if the value specified here does not have a protocol, then
  #           it is assumed to be a file protocol.
  #           Examples:
  #             url = /path/to/dir/or/file           # without protocol
  #             url = "file:///path/to/dir/or/file"  # with protocol
  # For other URLs: the URL will be read or written directly;
  # settings like "pattern", "recursive" and "fileNameFormat" will have no effect.
  # Finally, two other protocols defined in the DataStax Loader are be available:
  # - stdin:  the stdin protocol can be used to read from standard input;
  #           the only valid URL for this protocol is: "stdin:/".
  #           This protocol cannot be used for writing.
  #           Example:
  #             url = "stdin:/"
  # - stdout: the stdout protocol can be used to write to standard output;
  #           the only valid URL for this protocol is: "stdout:/".
  #           This protocol cannot be used for reading.
  #           Example:
  #             url = "stdout:/"
  url = ""

  # The glob pattern to use when searching for files to read.
  # Ignored when writing. Ignored for non-file URLs.
  # The syntax to use is the glob syntax, as described in
  # java.nio.file.FileSystem.getPathMatcher().
  # Only applicable when the "url" setting points to a directory
  # on a known filesystem, ignored otherwise.
  pattern = "**/*.csv"

  # The file name format to use when writing.
  # Ignored when reading. Ignored for non-file URLs.
  # The file name must comply with the formatting rules of
  # String.format(), and must contain a "%d" format specifier
  # that will be used to increment file name counters.
  fileNameFormat = "output-%0,6d.csv"

  # Whether to scan for files in subdirectories of the root directory.
  # Only applicable when the "url" setting points to a directory
  # on a known filesystem, ignored otherwise.
  # Ignored when writing.
  # Defaults to false.
  recursive = false

  # The maximum number of reading or writing threads.
  # In other words, this setting controls how many files
  # can be read or written simultaneously.
  maxThreads = 4

  # The file encoding to use.
  # Note that this setting applies to all files to be read and written.
  encoding = "UTF-8"

  # Whether the files to read or write begin with a header line or not.
  # Defaults to false (no header line).
  # When reading:
  #  - if set to true, the first non-empty line in every file is discarded,
  #    even if the "linesToSkip" setting is set to zero (see below).
  #    However, that line will be used to assign field names to
  #    each record, thus allowing mappings by field name such
  #    as "{ myFieldName1 = myColumnName1, myFieldName2 = myColumnName2 }".
  #  - if set to false, records will not contain field names,
  #    only (zero-based) field indexes; in this case,
  #    the mapping should be index-based, such
  #    as in "{ 0 = myColumnName1, 1 = myColumnName2}".
  # When writing:
  #  - if set to true: each file will begin with a header line;
  #  - if set to false, files will not contain a header line.
  # Note that this setting applies to all files to be read or written.
  header = false

  # The character to use as field delimiter.
  # Defaults to ',' (comma).
  # Only one character can be specified.
  # Note that this setting applies to all files to be read or written.
  delimiter = ","

  # The character used for quoting fields when the field delimiter is part of the field value.
  # Defaults to '"' (double quote).
  # Only one character can be specified.
  # Note that this setting applies to all files to be read or written.
  quote = "\""

  # The character used for escaping quotes inside an already quoted value.
  # Defaults to '\' (backslash).
  # Only one character can be specified.
  # Note that this setting applies to all files to be read or written.
  escape = "\\"

  # The character that represents a line comment when found in the beginning of a line of text.
  # Defaults to '\0', which disables this feature.
  # Only one character can be specified.
  # Note that this setting applies to all files to be read or written.
  comment = "\u0000"

  # Defines a number of lines to skip from each input file before the parser can begin to execute.
  # Defaults to zero (i.e., do not skip any lines)
  # Note that this setting applies to each input file individually.
  # Ignored when writing.
  linesToSkip = 0

  # Defines the maximum number of lines to read from or write to each file.
  # When reading, all lines past this number will be discarded.
  # When writing, files will contain at most this number of lines;
  # if more records remain to be written, a new file will be created
  # using the "fileNameFormat" setting.
  # Note that when writing to anything else than a directory,
  # this setting is ignored.
  # Defaults to -1, which disables this feature.
  # Note that this setting applies to each file individually.
  # This setting takes into account the "header" setting:
  # if a file begins with a header line, that line is counted.
  maxLines = -1

}
